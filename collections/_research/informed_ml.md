---
layout: research
title:  "Informed Machine Learning"
summary: "Auton Lab research frequently involves ways to incorporate expert knowledge into AI systems. This ranges from research on how to effectively have experts label vast amounts of data, to incorporating feedback in active learning frameworks, to formal verification of model adherence to domain-specific constraints and design specifications. We take AI outside the cozy spot of data-driven approach. Standard AI relies primarily on what can be learned from data, however, data is just a limited projection of reality. Auton lab is working on multiple exciting avenues to make AI and ML smarter."
splash: "/assets/images/tea_spec.png"
projects:
  - 
    name: Weak Supervision
    anchor: weasel
    blurb: "Many state of the art models have a voracious appetite for labeled data, which is hard to provide in contexts where subject matter experts are the only people capable of providing annotations. The weak supervision paradigm replaces labeling of individual data samples with the creation of labeling functions. Auton lab work expands this paradigm to increase the efficiency and flexibility of the data programming framework."
  -
    name: Active Learning
    anchor: active
    blurb: "Active search, Jeff, Andrew, Ina [blank]"
  -
    name: Semi-supervised Learning
    anchor: semisup
    blurb: "[blank]"
  -
    name: "Principle-Driven AI"
    anchor: principle
    blurb: "Leveraging domain knowledge; leveraging first principles of physics/chemistry/biology; leveraging common sense and demonstrating common sense. The utility of machine learning is that it will learn useful policies from data, however it is an open question of how to incorporate domain-specific constraints into the training process. Auton Lab works to help SMEs to codify their knowledge in a way that informs the model fitting process, including physics informed algorithms, as well as informing the testing process, including model-centric verification of adherence to design specifications and statistical evaluation of business metrics."
  -
    name: "Introspective AI"
    anchor: selfaware
    blurb: "Models should be conscious of their own decision logic, and able to admit what they can and cannot do. Building systems that exhibit algorithmic fairness."
---


<!-- Notes


-->


  
