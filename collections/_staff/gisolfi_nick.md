---
layout: homepage
first_name: Nick
last_name: Gisolfi
title: Project Scientist
category: staff
image: "/assets/images/gisolfi_nicholas.jpg"
summary: "Project Scientist"
---

I have been part of the Auton Lab since 2013 when I started my Masters at the RI working with Artur Dubrawki and mentored by Ina Fiterau.
I continued working with Artur for my PhD in 2015 and I graduated in December 2021.
Now I am a Project Scientist at the Auton Lab.

My dissertation focused on **Model-Centric Verification of Artificial Intelligence**.
In it, I lay out new methods for assessing whether an AI makes decisions in a similar way to how a trustworthy human would make their decision.
My goal with this work is to make AI more trustworthy and better suited to critical contexts, where it is important to provide assurances that AI will never inflict otherwise easily preventable harm to humans.
A longstanding and open question in machine learning is *what did the trained AI system actually learn from the data we gave it?* -- my work provides some answers to that question in application contexts that range from:

  - Radiation Safety - verifying whether, under the presence of adversarial noise, AI will detect vehicles that are concealing improperly contained radioactive isotopes
  - Critical Care Medicine - proving that an AI adheres to a clinician's expert knowledge and common-sense expectations
  - Algorithmic Fairness - proving that an AI does not yield substantially different recommendations for two individuals who are virtually identical except for immutable characteristics such as race or gender

I see an uncanny parallel between the history of the automobile industry and the current state of AI; in times before there were a set of criteria that determine what it means for a vehicle to be certified as road safe (seat belts, breakaway steering, airbags, etc) a lot of easily preventable harm was done to motorists.
By enforcing safety measures for new vehicles, they become safer and more ubiquitous.
I see a future for similar types of innovation in AI, where it will be much easier to warrant using AI in new critical contexts if we can prove that the sytem we wish to deploy is safe.

##### Manuscripts
My [PhD thesis][1]

##### Community
I am interested in community building, especially in academic contexts, which I interepret as fostering connections through shared experiences.
I enjoy organizing events that get people working towards common goals.

- [2018.HackAuton][2]
- [RI Robot Building Contest][3]

[1]:<https://www.ri.cmu.edu/publications/model-centric-verification-of-artificial-intelligence/>
[2]:<http://www.cs.cmu.edu/~ngisolfi/hackauton.html>
[3]:<http://www.cs.cmu.edu/~ngisolfi/orientation.html>

