---
layout: page
title: "Welcome"
---

Welcome to the Auton Lab!
We were founded by Andrew Moore in 1993.
Today, [our team](/people.md) is one of the largest applied machine learning research groups in academia.

Research at the Auton Lab is unique in that it aims to simultaneously address limitations of AI as a science and limitations of AI as a practice.
Limitations in practice are discovered through our persistent exposure to challenges in real-world [application areas](/application_areas.md).
These limitations translate into research opportunities, and our portfolio of fundamental [research thrusts](/research_areas.md) aims to provide answers to assuage the contemporary shortcomings of AI and make positive [impact](/impact_areas.md) across a variety of critical contexts.
Here are some of the biggest opportunities we see in the field of AI, as well as the types of questions we are asking and answering with our work.

<div class="welcome-container" markdown="1">

<h5>Trust in AI</h5>
  - <strong>Gap in practice</strong>: Users do not always trust AI in practice, and they tend to lose trust in AI systems when they fail in a way that inflicts otherwise easily preventable harm.
  - <strong>Gap in science</strong>: There is a general lack of systematic approaches to ascertain the trustworthiness of a trained model. Rates of error say nothing about the ways in which the errors manifest.
<h5>Understanding the AI Process and Results</h5>
  - <strong>Gap in practice</strong>: Users have a hard time understanding the reason that AI yields a particular output. It is difficult to explain the behavior of black box models because there are no conceptual components to communicate to end users.
  - <strong>Gap in science</strong>: Defining intermediate concepts that are useful in specific domains is difficult, and incorporating these concepts into the model's decision logic is even harder.
<h5>AI-Readiness of Data</h5>
  - <strong>Gap in practice</strong>: Data is only a projection of reality, and curating data that can be readily consumed by learning algorithms often requires prohibitive amounts of resources.
  - <strong>Gap in science</strong>: It is difficult to incorporate multiple data modalities, process data from archival formats to supervised learning tasks, and use humans effectively in labeling data for training reliable AI models.
<h5>Domain-Specific Constraints</h5>
  - <strong>Gap in practice</strong>: AI can produce predictions that violate fundamental truths of the universe (e.g., predicting blood pressure value that is negative).
  - <strong>Gap in science</strong>: Lack of methods to incorporate constraints during training of models or to enforce constraints at run-time. How can data-driven policy be informed with information that resides outside individual data?
<h5>Data Driven Discovery</h5>
  - <strong>Gap in practice</strong>: Providing answers for queries requires the queries to be well formed.
  - <strong>Gap in science</strong>: Frameworks for discovering unknown-unknowns and guiding humans to ask meaningful questions about their data and models.
<h5>Intelligent Data Structures and Efficient Learning Algorithms</h5>
  - <strong>Gap in practice</strong>: The capacity of computing infrastructure, availability of electricity, time, data that is required to build good models with one-size-fits-all solutions is often prohibitive, and prevents the widespread adoption of AI.
  - <strong>Gap in science</strong>: Methods to replicate the successes of deep learning in resource efficient ways. Methods to bring computing power to data rather than data to computing power.

</div>